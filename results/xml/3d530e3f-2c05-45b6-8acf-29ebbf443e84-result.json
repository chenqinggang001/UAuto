{"name": "demo,获取课程信息", "status": "broken", "statusDetails": {"message": "httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 400(int)\nassert_method: equal\nexpect_value: 200(int)", "trace": "self = <GetExamEndTime_test.TestGetExamEndTime object at 0x00000225FFCC5970>\nparam = None\n\n    def test_start(self, param: Dict = None) -> \"HttpRunner\":\n        \"\"\"main entrance, discovered by pytest\"\"\"\n        self.__init_tests__()\n        self.__project_meta = self.__project_meta or load_project_meta(\n            self.__config.path\n        )\n        self.__case_id = self.__case_id or str(uuid.uuid4())\n        self.__log_path = self.__log_path or os.path.join(\n            self.__project_meta.RootDir, \"logs\", f\"{self.__case_id}.run.log\"\n        )\n        log_handler = logger.add(self.__log_path, level=\"DEBUG\")\n    \n        # parse config name\n        config_variables = self.__config.variables\n        if param:\n            config_variables.update(param)\n        config_variables.update(self.__session_variables)\n        self.__config.name = parse_data(\n            self.__config.name, config_variables, self.__project_meta.functions\n        )\n    \n        if USE_ALLURE:\n            # update allure report meta\n            allure.dynamic.title(self.__config.name)\n            allure.dynamic.description(f\"TestCase ID: {self.__case_id}\")\n    \n        logger.info(\n            f\"Start to run testcase: {self.__config.name}, TestCase ID: {self.__case_id}\"\n        )\n    \n        try:\n>           return self.run_testcase(\n                TestCase(config=self.__config, teststeps=self.__teststeps)\n            )\n\nvenv\\lib\\site-packages\\httprunner\\runner.py:455: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nvenv\\lib\\site-packages\\httprunner\\runner.py:357: in run_testcase\n    extract_mapping = self.__run_step(step)\nvenv\\lib\\site-packages\\httprunner\\runner.py:295: in __run_step\n    step_data = self.__run_step_request(step)\nvenv\\lib\\site-packages\\httprunner\\runner.py:208: in __run_step_request\n    resp_obj.validate(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <httprunner.response.ResponseObject object at 0x00000225FFD29910>\nvalidators = [{'equal': ['status_code', 200, '']}]\nvariables_mapping = {'HOST': 'https://utestapi.tongshike.cn', 'OpenPaper': {'code': 1, 'message': '成功', 'result': {'addTime': 0, 'autoSave... 0, 'commitPaperTime': 0, 'createTime': 1633751255000, 'deprecatedPaper': '', ...}, ...}}, 'attendanceID': 265434, ...}\nfunctions_mapping = {'Merge': <function Merge at 0x00000225FFA3EAF0>, 'get_Nowtime': <function get_Nowtime at 0x00000225FFA3EC10>, 'get_en...get_env at 0x00000225FFA3E790>, 'get_httprunner_version': <function get_httprunner_version at 0x00000225FE6964C0>, ...}\n\n    def validate(\n        self,\n        validators: Validators,\n        variables_mapping: VariablesMapping = None,\n        functions_mapping: FunctionsMapping = None,\n    ) -> NoReturn:\n    \n        variables_mapping = variables_mapping or {}\n        functions_mapping = functions_mapping or {}\n    \n        self.validation_results = {}\n        if not validators:\n            return\n    \n        validate_pass = True\n        failures = []\n    \n        for v in validators:\n    \n            if \"validate_extractor\" not in self.validation_results:\n                self.validation_results[\"validate_extractor\"] = []\n    \n            u_validator = uniform_validator(v)\n    \n            # check item\n            check_item = u_validator[\"check\"]\n            if \"$\" in check_item:\n                # check_item is variable or function\n                check_item = parse_data(\n                    check_item, variables_mapping, functions_mapping\n                )\n                check_item = parse_string_value(check_item)\n    \n            if check_item and isinstance(check_item, Text):\n                check_value = self._search_jmespath(check_item)\n            else:\n                # variable or function evaluation result is \"\" or not text\n                check_value = check_item\n    \n            # comparator\n            assert_method = u_validator[\"assert\"]\n            assert_func = get_mapping_function(assert_method, functions_mapping)\n    \n            # expect item\n            expect_item = u_validator[\"expect\"]\n            # parse expected value with config/teststep/extracted variables\n            expect_value = parse_data(expect_item, variables_mapping, functions_mapping)\n    \n            # message\n            message = u_validator[\"message\"]\n            # parse message with config/teststep/extracted variables\n            message = parse_data(message, variables_mapping, functions_mapping)\n    \n            validate_msg = f\"assert {check_item} {assert_method} {expect_value}({type(expect_value).__name__})\"\n    \n            validator_dict = {\n                \"comparator\": assert_method,\n                \"check\": check_item,\n                \"check_value\": check_value,\n                \"expect\": expect_item,\n                \"expect_value\": expect_value,\n                \"message\": message,\n            }\n    \n            try:\n                assert_func(check_value, expect_value, message)\n                validate_msg += \"\\t==> pass\"\n                logger.info(validate_msg)\n                validator_dict[\"check_result\"] = \"pass\"\n            except AssertionError as ex:\n                validate_pass = False\n                validator_dict[\"check_result\"] = \"fail\"\n                validate_msg += \"\\t==> fail\"\n                validate_msg += (\n                    f\"\\n\"\n                    f\"check_item: {check_item}\\n\"\n                    f\"check_value: {check_value}({type(check_value).__name__})\\n\"\n                    f\"assert_method: {assert_method}\\n\"\n                    f\"expect_value: {expect_value}({type(expect_value).__name__})\"\n                )\n                message = str(ex)\n                if message:\n                    validate_msg += f\"\\nmessage: {message}\"\n    \n                logger.error(validate_msg)\n                failures.append(validate_msg)\n    \n            self.validation_results[\"validate_extractor\"].append(validator_dict)\n    \n        if not validate_pass:\n            failures_string = \"\\n\".join([failure for failure in failures])\n>           raise ValidationFailure(failures_string)\nE           httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\nE           check_item: status_code\nE           check_value: 400(int)\nE           assert_method: equal\nE           expect_value: 200(int)\n\nvenv\\lib\\site-packages\\httprunner\\response.py:273: ValidationFailure"}, "description": "TestCase ID: 2ed00c12-ca86-4603-87cc-7437a7a9d560", "steps": [{"name": "step: 获取考试id", "status": "passed", "steps": [{"name": "step: 获取考试id", "status": "passed", "steps": [{"name": "step: 获取考试id", "status": "passed", "steps": [{"name": "step: 获取学生考试列表", "status": "passed", "start": 1634551413201, "stop": 1634551413356}], "start": 1634551413199, "stop": 1634551413357}, {"name": "step: 进入考试须知页面", "status": "passed", "start": 1634551413358, "stop": 1634551413412}], "start": 1634551413198, "stop": 1634551413413}, {"name": "step: 进入考试须知页面", "status": "passed", "start": 1634551413413, "stop": 1634551413572}], "start": 1634551413196, "stop": 1634551413572}, {"name": "step: 获取考试结束时间", "status": "broken", "statusDetails": {"message": "httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 400(int)\nassert_method: equal\nexpect_value: 200(int)\n", "trace": "  File \"D:\\my_hrun\\my_hrun_env\\venv\\lib\\site-packages\\httprunner\\runner.py\", line 357, in run_testcase\n    extract_mapping = self.__run_step(step)\n  File \"D:\\my_hrun\\my_hrun_env\\venv\\lib\\site-packages\\httprunner\\runner.py\", line 295, in __run_step\n    step_data = self.__run_step_request(step)\n  File \"D:\\my_hrun\\my_hrun_env\\venv\\lib\\site-packages\\httprunner\\runner.py\", line 208, in __run_step_request\n    resp_obj.validate(\n  File \"D:\\my_hrun\\my_hrun_env\\venv\\lib\\site-packages\\httprunner\\response.py\", line 273, in validate\n    raise ValidationFailure(failures_string)\n"}, "start": 1634551413573, "stop": 1634551413614}], "attachments": [{"name": "stderr", "source": "9cd61768-4cd4-4949-9b73-ee7f165fea2a-attachment.txt", "type": "text/plain"}], "start": 1634551413190, "stop": 1634551413616, "uuid": "1e8be1cf-d248-4747-b8da-5acd4800932d", "historyId": "e637b94972a7294a8576c9d55a1d1010", "testCaseId": "5f0ecd805ec4a4926ca75a58ca6254a5", "fullName": "testcases.Exams.ExamController.GetExamEndTime_test.TestGetExamEndTime#test_start", "labels": [{"name": "parentSuite", "value": "testcases.Exams.ExamController"}, {"name": "suite", "value": "GetExamEndTime_test"}, {"name": "subSuite", "value": "TestGetExamEndTime"}, {"name": "host", "value": "LAPTOP-R6V6RJC2"}, {"name": "thread", "value": "10836-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "testcases.Exams.ExamController.GetExamEndTime_test"}]}